// 为了确保我们的应用程序在困难条件下比如低端设备和网络连接差也能尽可能高效地加载，我们可以使用 PRPL 模式。

/**
 * PRPL关注四点:
 * 高效推送关键资源，最大限度减少服务器往返次数并减少加载时间
 * 尽快渲染路线来改善用户体验
 * 后台预先缓存访问率高的资源，最大限度减少服务器访问量
 * 延迟加载不频繁的请求
 */

// 当我们想要访问一个网站时，我们首先必须向服务器发出请求以获取这些资源。入口点指向的文件从服务器返回，这通常是我们应用程序的初始 HTML 文件！浏览器的 HTML 解析器在开始从服务器接收数据后立即开始解析这些数据。如果解析器发现需要更多资源，例如样式表或脚本，则会向服务器发送另一个 HTTP 请求以获取这些资源！

// 长期以来，我们使用 HTTP/1.1 来进行客户端和服务器之间的通信。尽管 HTTP/1.1 与 HTTP/1.0 相比引入了许多改进，例如能够在发送带有标头的新 HTTP 请求之前保持客户端和服务器之间的 TCP 连接处于活动状态keep-alive，但仍有一些问题需要解决！

// HTTP/2 相对于 HTTP/1.1 引入了一些重大的变化，这使得我们更容易优化客户端和服务器之间的消息交换。

/**
 * HTTP/1.1在req和res之间使用换行符分隔的纯文本协议，而HTTP/2将req和res拆分为帧的叫小部分，包含标头和正文字段的HTTP请求至少拆分为两个帧: 标头帧和数据帧！
 * HTTP/1.1 客户端和服务器之间的 TCP 连接数量最多为 6 个。在通过同一 TCP 连接发送新请求之前，必须先解决上一个请求！如果上一个请求需要很长时间才能解决，则该请求会阻止其他请求的发送。这种常见问题称为队头阻塞，会增加某些资源的加载时间！
 * HTTP/2 使用双向流，这使得一个包含多个双向流的 TCP 连接成为可能，这些双向流可以在客户端和服务器之间传输多个请求和响应帧！
 * 一旦服务器收到该特定请求的所有请求帧，它就会重新组合这些帧并生成响应帧。这些响应帧被发送回客户端，客户端会重新组合这些帧。由于流是双向的，我们可以通过同一个流发送请求帧和响应帧。
 * HTTP/2通过允许在前一个请求解析之前在同一个TCP连接上发送多个请求来解决队头阻塞问题。
 * HTTP/2 还引入了一种更优化的数据获取方式，称为服务器推送。服务器不必每次都通过发送 HTTP 请求明确请求资源，而是可以通过“推送”这些资源自动发送额外的资源。
 * 客户端收到新增的资源后，会把这些资源存放到浏览器的缓存中，当解析入口文件时发现这些资源时，浏览器就可以快速的从缓存中获取资源，而不需要再向服务器发起 HTTP 请求！
虽然推送资源可以减少接收额外资源的时间，但服务器推送并不支持 HTTP 缓存！下次我们访问网站时，推送的资源将无法使用，必须再次请求。为了解决这个问题，PRPL 模式在初始加载后使用服务工作线程来缓存这些资源，以确保客户端不会发出不必要的请求。
 */